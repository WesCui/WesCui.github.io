

# NDDL复习

## BP算法

### 1. 反向传播算法的变形

- **目的**：提高反向传播算法的训练效率和收敛速度。

- **理论和实例**：
  
  - **基本反向传播算法**：在实际问题中训练时间长。
  
  基本反向传播算法（Backpropagation Algorithm）是一种用于训练多层前馈神经网络的算法。它通过计算网络输出与期望输出之间的误差，并利用这个误差来更新网络中的权重和偏置，以最小化误差。首先初始化、前向传播、计算误差、反向传播误差、更新权重和偏置、不断迭代。
  
  缺点：BP（反向传播）算法虽然在神经网络训练中广泛应用，但也存在一些缺点和局限性：
  
  1. **收敛速度慢**：
     - BP算法通常需要大量的迭代才能收敛到最小误差，这使得训练过程可能非常缓慢。
  
  2. **易陷入局部最小值**：
     - 由于BP算法基于梯度下降，它可能会在误差曲面的局部最小值处停止，而不是全局最小值。这意味着最终的网络性能可能不是最优的。
  
  3. **对初始权重敏感**：
     - BP算法的收敛性和最终结果很大程度上依赖于初始权重的选择。不良的初始权重可能导致训练失败或收敛到较差的解。
  
  4. **学习率的选择**：
     - 学习率的选择对算法的性能有很大影响。学习率太小会导致收敛速度慢，太大则可能导致算法发散。
  
  5. **过拟合风险**：
     - BP算法可能会过度拟合训练数据，导致网络在未见过的数据上表现不佳。
  
  6. **计算复杂度高**：
     - 对于大型网络或数据集，BP算法的计算复杂度较高，需要大量的计算资源。
  
  7. **性能曲面的复杂性**：
     - 多层网络的性能曲面可能非常复杂，存在多个局部极小值和鞍点，这使得优化过程复杂且不确定。
  
  8. **对称性问题**：
     - 在多层网络中，对称性可能导致某些权重配置成为鞍点，从而影响算法的收敛性。
  
  9. **批量处理的局限性**：
     - 虽然批量处理可以提供更精确的梯度估计，但它需要在整个训练集上进行多次前向和反向传播，这可能导致内存和计算资源的限制。
  
  这些缺点促使研究者开发出多种改进方法，如引入动量、可变学习率、共轭梯度法和Levenberg-Marquardt算法等，以提高BP算法的效率和效果。
  
  ---
  
  - **快速算法研究**：分为两类，启发式信息技术和基于数值优化技术。
  
  启发式：**可变学习速度**：动态调整学习率以适应训练过程中的不同阶段。**动量方法**：通过添加动量项来平滑权重更新过程，减少振荡，加速收敛。**可变比例变量**：调整网络中不同部分的学习速度，以优化整体性能。
  
  ​	基于数值优化技术：
  
  这类方法将标准数值优化技术应用于多层感知机训练，以提高算法的收敛速度和稳定性。主要包括：
  
  - **共轭梯度法**：一种不需要计算二阶导数的优化方法，具有二次收敛特性，通常比最速下降法更快。通常需要较少的迭代次数来收敛，但每次迭代的计算量可能较大。
  - **Levenberg-Marquardt算法**：牛顿法的一种改进，特别适合于神经网络训练。它结合了最速下降法的稳定性和牛顿法的快速收敛性。在每次迭代时的计算量较大，但对于中等数量的网络参数，它是最快的神经网络训练算法之一。
  
  ---
  
  - **SDBP（最速下降反传算法）**：所有算法都使用反向传播过程，区别在于如何用导数修改权值。
  
  - **性能曲面**：多层网络的性能曲面可能会存在多个局部极小值点，这使得SDBP算法在多层网络中的表现与单层线性网络完全不同。
  
  - **初始参数设置**：由于多层网络的对称性，0成为性能曲面的一个鞍点。因此，设置SDBP网络初始参数时不能设置为0，也不能设置过大，可以选择小的随机值作初始值。
  
  - 整个训练集都出现后，网络才进行更新。每个训练例子的梯度被平均在一起，以获得更精确的梯度估计
  
  - 改进方法
  
    - **调整学习速度**：在平坦区域加大学习速度，在斜率增加时减小学习速度，以提高收敛性。
    - **平滑轨迹**：算法开始发散时，在窄谷内震荡，若用平均改变参数的方法过滤轨迹，可以平滑掉震荡并产生平滑轨迹。
  
    ---

### 6. 网络训练和推广能力
- **推广能力**：网络对未在训练集中出现的样本做出正确反应的能力。
- **过拟合现象**：学习了过多的特殊样本，过分追求训练集内误差小，丧失推广能力。
- **影响推广能力的因素**：训练样本的质量和数量、网络结构、问题本身的复杂程度。
- 在多层前馈神经网络中，性能曲面是非凸的，这导致反向传播算法在训练过程中可能面临收敛性问题、梯度消失和爆炸问题，以及过拟合和泛化能力差等问题。

### 7. 网络规模选择
- **改变网络结构的途径**：逐步增大或逐步修剪法，正则化约束。
- **值得注意的问题**：训练的网络在其它样本上的误差与在训练样本上的误差不一样，应使用测试集来检验网络的性能。







# 联想学习



这份文件是关于联想学习的，涵盖了无监督学习规则及其在神经网络中的应用。以下是详细的知识点总结：

### 1. 联想学习的目的
- **目的**：介绍无监督学习的简单规则，使网络能够学习频繁一同出现的模式之间的关联。这种关联使得网络能够执行模式识别、回忆等任务。一旦学习成功，这种关联将使得网络能够执行
  包括模式识别、回忆等任务。

### 2. 理论和实例
- **刺激/响应关联**：系统输入和输出之间的任何联系。当模式A输入系统时，系统将产生响应模式B。
- **行为心理学派**：关联构成了行为心理学派的基础，利用联想和学习联想的规则来解释动物和人类的行为。
- **巴甫洛夫的经典实验**：利用喂食时摇铃训练狗对铃声的反应，这是一个典型的条件反射例子。
- **Donald Hebb的假设**：当细胞A的轴突足够接近并刺激细胞B，且反复地或持续地刺激细胞B，那么在这两个细胞或其中一个细胞中会发生某种增长过程或代谢作用，以增加细胞A对细胞B的刺激效果。

### 3. 联想学习的贡献者
- **Tuevo Kohenen、James Anderson和Stephen Grossberg**：对联想学习的发展做出了贡献。Anderson和Kohenen提出了线性联想器网络，Grossberg引入了非线性连续联想网络。

### 4. 简单联想网络
- **单输入硬极限联想器**：限制p的值为1或0，以表示是否有刺激。a被限定为同样的值，以表示网络是否有响应。
- **无条件刺激与条件刺激**：无条件刺激类似于巴甫洛夫实验中给狗的食物，条件刺激类似于巴甫洛夫实验中的铃声。

### 5. 无监督的Hebb规则
- **Hebb规则**：根据神经元的输入和输出的乘积，按比例增加权值。学习速度决定着联想关系建立前刺激和响应同时发生的次数。同时激活的神经元之间的连接会被加强”
- 权值更新

  ：无监督Hebb规则通过输入和输出的乘积来更新权值。具体来说，如果输入向量为**p**，输出向量为**a**，则权值更新公式为：
  $$
  w(q)=w(q−1)+αa(q)p(q)
  $$
  
- **Hebb规则的向量形式**：在每次迭代中，先根据输入计算响应输出，再根据Hebb规则更新权值。
- **Hebb规则的缺点**：权值趋于无限大，没有使权值下降的机制。
- ### 特点

  - **局部学习规则**：无监督Hebb规则只用到了包含被更新权值所在层的信号，因此是一种局部学习规则。
  - **强化同时激活的连接**：当输入和输出同时激活时，相应的权值会被增加，从而强化这种连接

### 6. 带衰减的Hebb规则
- **改进Hebb规则**：加入权值的衰减项，使得权值矩阵不会无限制地增加。
- **最大权值**：由衰减率决定。对所有输入和输出都设为1（最大化学习），然后求解稳态权值。

### 7. 简单的识别网络
- **instar神经元**：有向量输入的神经元被称为instar，是最简单的模式识别网络。一种简单的识别网络，具有单个输入和多个输出。它的输出取决于输入向量与权值向量的内积。当输入向量与权值向量的内积大于等于某个阈值时，神经元被激活。
- **instar规则**：为了在获得权值衰减的同时限制遗忘问题，可以加上一个与输出成比例的衰减项。

### 8. Kohonen规则
- **Kohonen规则**：与instar规则相似，允许神经元的权值学习输入向量，适合于识别应用。

- ```
  它是一种无监督学习算法，能够将高维数据映射到低维空间（通常是二维），同时保持数据在高维空间中的拓扑关系。
  
  工作原理
  初始化权重向量: 每个神经元都关联一个权重向量，初始值通常随机生成。
  选取输入向量: 从数据集随机选取一个输入向量。
  计算距离: 计算输入向量与每个神经元的权重向量之间的距离。
  寻找最佳匹配单元（BMU）: 找到与输入向量距离最小的神经元，即BMU。
  更新权重:
  更新BMU的权重: 将BMU的权重向量向输入向量方向移动。
  更新BMU的邻居的权重: BMU的邻居的权重向量也向输入向量方向移动，但移动幅度小于BMU。邻居的范围随着迭代次数的增加逐渐缩小。
  重复上述过程: 重复步骤2-5，直到满足停止条件（例如，权重变化小于某个阈值）。
  核心思想
  自组织: 神经元通过竞争和合作的方式，自发地组织成一个拓扑结构，使得相似的输入向量被映射到相邻的神经元。
  拓扑保持: 映射后的低维空间保持了原始高维数据的主要特征和拓扑关系。
  优点
  无监督学习: 不需要预先标注的数据。
  可视化: 可以将高维数据映射到二维平面，方便可视化和分析。
  发现数据内在结构: 能够发现数据中的聚类和非线性关系。
  ```

  

### 9. 简单回忆网络
- **outstar网络**：有一个标量输入和一个向量输出，可以利用一个刺激和向量响应之间的联想完成模式回忆。

### 10. 小结
- **联想学习规则**：包括无监督的Hebb规则、带衰减的Hebb规则、instar规则、Kohonen规则和outstar规则。

这些知识点涵盖了联想学习的基本概念、理论基础、学习规则及其在神经网络中的应用。





---



## 竞争学习网络（Competitive Learning Network）

### 什么是竞争学习网络？

竞争学习网络是一种无监督学习的神经网络模型。在这个模型中，神经元之间存在竞争关系，当网络接收到一个输入时，神经元会相互竞争，最终只有一个或少数几个神经元获胜。获胜的神经元会调整自己的权重，使得下次遇到类似的输入时，它更有可能再次获胜。

### 竞争学习的原理

- 竞争机制：
  - 当网络接收到一个输入时，每个神经元都会计算自己与输入的相似度。
  - 相似度最高的那个神经元获胜。
- 权重更新：
  - 只有获胜的神经元会更新自己的权重，使得它与输入更加相似。
  - 获胜神经元的权重朝着输入的方向移动。

### 竞争学习的应用

- **聚类分析：** 竞争学习网络可以将相似的输入样本聚类到一起，从而发现数据中的内在结构。
- **特征提取：** 通过竞争学习，可以提取数据的关键特征。
- **模式识别：** 竞争学习网络可以用于模式识别任务，比如图像识别、语音识别等。

### 竞争学习的优点

- **简单易实现：** 竞争学习算法相对简单，易于实现。
- **无监督学习：** 不需要标注数据，可以从大量未标注的数据中学习。
- **发现数据内在结构：** 可以发现数据中的自然聚类和特征。

### 竞争学习的缺点

- **局部最小值：** 竞争学习容易陷入局部最小值，导致学习效果不佳。
- **对初始权重的敏感性：** 初始权重的选择会影响最终的聚类结果。
- **无法处理重叠的类别：** 对于重叠的类别，竞争学习很难给出准确的分类结果。

### 竞争学习的典型网络结构

- **Kohonen自组织映射 (SOM)：** SOM是一种经典的竞争学习网络，它将高维数据映射到低维空间，同时保持数据的拓扑关系。

### 总结

竞争学习网络是一种强大的无监督学习工具，它通过神经元之间的竞争，能够自动发现数据中的内在结构。尽管存在一些局限性，但竞争学习在很多领域都有着广泛的应用。

---

## Hamming网络：一种用于模式识别的神经网络

### Hamming网络是什么？

Hamming网络是一种基于Hamming距离的联想记忆神经网络。它主要用于模式识别任务，特别擅长处理含有噪声或部分缺失信息的模式。

### Hamming距离

Hamming距离是用于衡量两个等长字符串之间差异的度量。在Hamming网络中，每个模式都被表示为一个二进制向量。Hamming距离就是这两个二进制向量中对应位不同的数量。

### Hamming网络的工作原理

1. **存储模式：** 将要识别的模式以二进制向量的形式存储在网络中。每个模式对应一个存储单元。
2. **输入模式：** 当输入一个待识别的模式时，网络会计算输入模式与存储的每个模式之间的Hamming距离。
3. **输出模式：** Hamming距离最小的那个存储模式被认为是输入模式所对应的模式。

### Hamming网络的优点

- **抗噪声能力强：** 由于基于Hamming距离的比较，Hamming网络对输入模式中的噪声具有较强的鲁棒性。
- **并行处理：** Hamming网络的计算可以并行进行，提高了处理速度。
- **结构简单：** 网络结构简单，易于实现。

### Hamming网络的缺点

- **存储容量有限：** 存储容量与网络规模有关，对于大规模的模式识别任务，存储容量可能不足。
- **不能处理连续值：** Hamming网络只能处理离散的二进制向量，对于连续值的数据需要进行离散化处理。
- **对模式的相似性敏感：** 如果两个模式过于相似，网络可能难以区分。

### Hamming网络的应用

- **模式识别：** 图像识别、字符识别、语音识别等。
- **关联记忆：** 根据部分信息恢复完整的模式。
- **数据压缩：** 通过编码将数据转换为Hamming距离较小的向量，实现数据压缩。

### 总结

Hamming网络是一种简单有效的模式识别神经网络。它通过计算输入模式与存储模式之间的Hamming距离来实现模式识别。尽管存在一些局限性，但Hamming网络在某些特定场景下仍然具有较好的应用价值。

---

## 竞争层：神经网络中的“胜者为王”

### 什么是竞争层？

在神经网络中，竞争层是一个特殊的层，其中的神经元会相互竞争，最终只有一个或少数几个神经元“胜出”。这个“胜出”的神经元通常代表着当前输入数据所属的类别或特征。

### 竞争层的运作方式

1. **计算距离：** 当一个输入数据进入网络时，竞争层中的每个神经元都会计算自己与输入数据之间的距离（通常是欧几里得距离）。
2. **选出胜者：** 距离最小的神经元被认为是“胜者”。
3. **权重更新：** 只有“胜者”的神经元会更新自己的权重，使得下次遇到类似的输入时，它更有可能再次“胜出”。

### 竞争层的作用

- **聚类分析：** 竞争层可以将相似的输入数据聚类到一起，从而发现数据中的内在结构。
- **特征提取：** 通过竞争学习，可以提取数据的关键特征。
- **模式识别：** 竞争层可以用于模式识别任务，比如图像识别、语音识别等。

### 竞争层在神经网络中的位置

竞争层通常位于神经网络的中间层，起到特征提取和分类的作用。它可以与其他类型的层（如全连接层、卷积层）结合使用，构建更复杂的网络结构。

### 竞争层的典型应用

- **自组织映射 (SOM)：** SOM是一种经典的竞争学习网络，它将高维数据映射到低维空间，同时保持数据的拓扑关系。
- **学习向量量化 (LVQ)：** LVQ是一种有监督的学习算法，它通过竞争学习的方式来进行分类。

### 竞争层的优势

- **无监督学习：** 不需要标注数据，可以从大量未标注的数据中学习。
- **发现数据内在结构：** 可以发现数据中的自然聚类和特征。
- **实现聚类和分类：** 竞争层可以同时实现聚类和分类的功能。

### 竞争层的局限性

- **局部最小值：** 竞争学习容易陷入局部最小值，导致学习效果不佳。
- **对初始权重的敏感性：** 初始权重的选择会影响最终的聚类结果。
- **无法处理重叠的类别：** 对于重叠的类别，竞争学习很难给出准确的分类结果。

---

## 自组织特征映射（Self-Organizing Map, SOM）

### 什么是SOM？

SOM是一种无监督学习的神经网络模型，它通过模拟大脑皮层神经元的自组织过程，将高维数据映射到低维空间（通常是二维），同时保持数据在高维空间中的拓扑关系。换句话说，SOM可以帮助我们发现数据中的内在结构，并将其可视化。

### SOM的工作原理

1. **初始化权重:** 网络中的每个神经元都有一个权重向量，初始值通常随机生成。
2. **选取输入向量:** 从数据集随机选取一个输入向量。
3. **寻找最佳匹配单元（BMU）:** 计算输入向量与每个神经元的权重向量之间的距离，距离最小的神经元即为BMU。
4. 更新权重:
   - BMU的权重向输入向量方向移动。
   - BMU的邻域内的神经元的权重也向输入向量方向移动，但移动幅度小于BMU。
5. **重复:** 重复步骤2-4，直到满足停止条件。

### SOM的优势

- **无监督学习:** 不需要预先标注的数据。
- **可视化:** 可以将高维数据映射到二维平面，方便可视化和分析。
- **发现数据内在结构:** 能够发现数据中的聚类和非线性关系。
- **拓扑保持:** 映射后的低维空间保持了原始高维数据的主要特征和拓扑关系。

### SOM的应用

- **数据可视化:** 将高维数据降维，方便可视化。
- **聚类分析:** 将相似的数据样本聚在一起。
- **特征提取:** 从高维数据中提取出有用的特征。
- **异常检测:** 识别与其他数据样本差别较大的样本。

### SOM与竞争层的联系

SOM可以看作是一种特殊的竞争学习网络。在SOM中，每个神经元都与其他神经元竞争，最终只有距离输入向量最近的神经元（BMU）获胜。获胜的神经元及其邻域的神经元会更新权重，使得网络能够更好地适应输入数据。

**SOM与K-means的区别:** SOM和K-means都是聚类算法，但SOM更强调拓扑关系的保持，而K-means则更关注聚类的中心。

**如何选择SOM的网络参数:** 网络大小、学习率、邻域大小等参数的选择都会影响SOM的性能，需要根据具体问题进行调整。

**SOM的缺点:** SOM对初始权重的选择比较敏感，而且容易陷入局部最小值。

---

## Hopfield网络：一种联想记忆的神经网络

### 什么是Hopfield网络？

Hopfield网络是一种递归神经网络，它通过模拟人类大脑的联想记忆功能，能够存储并恢复模式。Hopfield网络可以看作是一种特殊的能量网络，网络中的每个状态都对应一个能量值，网络的运行过程就是寻找能量最低的状态。

### Hopfield网络的工作原理

1. **存储模式：** 将要存储的模式（如图像、文本等）转换为二进制向量，然后根据这些向量计算网络的连接权重。
2. **输入模式：** 将一个不完整的或带有噪声的模式作为初始状态输入网络。
3. **异步更新：** 神经元按照随机或固定的顺序依次更新状态，直到网络达到稳定状态。
4. **输出模式：** 稳定状态下的网络状态即为恢复的模式。

### Hopfield网络的优点

- **联想记忆：** 可以根据部分信息恢复完整的模式。
- **抗噪声能力：** 对输入模式中的噪声具有一定的容错能力。
- **结构简单：** 网络结构简单，易于实现。

### Hopfield网络的缺点

- **存储容量有限：** 存储容量与网络规模有关，对于复杂模式的存储能力有限。
- **易陷入局部最小值：** 网络可能收敛到一个错误的稳定状态，而不是最优的存储模式。
- **只能存储二值模式：** 传统的Hopfield网络只能处理二值向量，对于连续值的数据需要进行离散化处理。

### Hopfield网络的应用

- **模式识别：** 图像识别、字符识别等。
- **优化问题：** 求解旅行商问题等优化问题。
- **关联记忆：** 根据部分信息恢复完整的模式。

### Hopfield网络与其他神经网络的关系

- **与玻尔兹曼机的关系：** Hopfield网络可以看作是玻尔兹曼机的一种特例。
- **与自组织映射的关系：** 两者都是无监督学习的网络，但SOM更侧重于数据可视化和聚类，而Hopfield网络则更侧重于联想记忆。

### 总结

Hopfield网络是一种经典的神经网络模型，它为我们提供了一种模拟人类记忆的思路。尽管存在一些局限性，但Hopfield网络在模式识别、优化问题等领域仍然具有重要的应用价值。

## Hopfield网络的相关问题解答

### Hopfield网络的能量函数是什么？

Hopfield网络的能量函数是一个标量函数，用来衡量网络的状态。能量函数的表达式为：

```
E = -1/2 * ∑(i,j) w_ij * s_i * s_j
```

其中：

- `E`：能量函数
- `w_ij`：神经元i和j之间的连接权重
- `s_i`，`s_j`：神经元i和j的状态（通常为-1或1）

能量函数的物理意义是表示网络的稳定程度。网络的运行过程就是寻找能量最低的状态，也就是最稳定的状态。

### 如何计算Hopfield网络的连接权重？

Hopfield网络的连接权重通常采用Hebb学习规则来计算。对于一个存储模式向量`xi`，其对应的权重更新公式为：

```
w_ij = w_ij + xi_i * xi_j
```

其中：

- `w_ij`：神经元i和j之间的连接权重
- `xi_i`，`xi_j`：模式向量`xi`中神经元i和j的值

对于多个模式向量，可以将每个模式向量对应的权重增量相加，得到最终的连接权重矩阵。

### Hopfield网络与自联想网络有什么区别？

Hopfield网络和自联想网络本质上是相同的。它们都是通过存储模式的特征，来实现对输入模式的联想和恢复。二者的区别主要在于侧重点和应用场景：

- **Hopfield网络** 更强调能量函数的最小化，通过寻找能量最低的状态来实现模式恢复。
- **自联想网络** 更强调模式的自动关联，通过学习输入模式的特征，来实现对缺失部分的补全。

### 如何提高Hopfield网络的存储容量？

提高Hopfield网络的存储容量是一个研究热点，目前还没有完美的解决方案。以下是一些常用的方法：

- **稀疏编码:** 将模式向量转换为稀疏表示，可以提高存储容量。
- **梯度下降法:** 使用梯度下降法来优化连接权重，可以提高网络的泛化能力。
- **引入噪声:** 在训练过程中引入噪声，可以提高网络的鲁棒性。
- **改进能量函数:** 设计更复杂的能量函数，可以提高网络的存储能力。



### Hopfield网络解决TSP问题的思路

- **将TSP问题转化为能量最小化问题：** Hopfield网络的本质是寻找能量函数的最小值。因此，我们需要将TSP问题中的路径长度转化为一个能量函数。

- **设计神经网络结构：** 网络中的每个神经元对应一个城市，神经元的状态表示是否经过该城市。

- 定义能量函数：

   能量函数的设计是关键，它需要满足以下条件：

  - 当网络处于合法路径状态时，能量函数值较小。
  - 当网络处于非法路径状态时，能量函数值较大。

- **网络演化：** 通过迭代更新神经元的状态，使得网络的能量逐渐降低，最终收敛到一个能量最小值的状态，此时对应于一条可能的TSP最优路径。

Hopfield网络并不能保证一定找到全局最优解，只能找到一个局部最优解。

能量函数的设计直接影响到算法的性能，需要根据具体问题进行调整。

对于大规模的TSP问题，Hopfield网络的计算复杂度可能过高。